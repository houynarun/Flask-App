

import os
import warnings
import multiprocessing
import math


from app 				import app,db

from sqlalchemy.orm 	import scoped_session
from sqlalchemy.orm 	import sessionmaker
from sqlalchemy 		import create_engine,inspect, exc, event
from sqlalchemy.pool 	import NullPool
from app.Setting.models	import *
import time
from functools 			import partial
from multiprocessing import Pool,TimeoutError,Manager

class CLS_CONNECTION_GUARD():
	"""docstring for CLS_CONNECTION_GUARD"""
	def __init__(self):
		# self.engine = create_engine(CONF.CONNECTION_STRING)
		self.engine = create_engine(app.config.get("SQLALCHEMY_DATABASE_URI"),poolclass=NullPool)
		self.add_engine_pidguard(self.engine)
		session_factory = sessionmaker(bind=self.engine)
		self.ThreadS = scoped_session(session_factory)

	def dispose(self):
		self.engine.dispose()
		self.ThreadS.close()
		self.ThreadS.remove()

	def add_engine_pidguard(self,engine):
		"""Add multiprocessing guards.

		Forces a connection to be reconnected if it is detected
		as having been shared to a sub-process.

		"""

		@event.listens_for(engine, "connect")
		def connect(dbapi_connection, connection_record):
			connection_record.info['pid'] = os.getpid()

		@event.listens_for(engine, "checkout")
		def checkout(dbapi_connection, connection_record, connection_proxy):
			pid = os.getpid()
			if connection_record.info['pid'] != pid:
				# substitute log.debug() or similar here as desired
				warnings.warn(
					"Parent process %(orig)s forked (%(newproc)s) with an open "
					"database connection, "
					"which is being discarded and recreated." %
					{"newproc": pid, "orig": connection_record.info['pid']})
				connection_record.connection = connection_proxy.connection = None
				raise exc.DisconnectionError(
					"Connection record belongs to pid %s, "
					"attempting to check out in pid %s" %
					(connection_record.info['pid'], pid)
				)



def runMultiprocessing(FuncGetRecordList, FuncProcess, NumOfRecord, PageSize=0, PassObj=False,PassField="ID", Param1={}, Param2={}):
	try:
		CPU 	=	getNumberOfCoreCPU()

		# calculate page size
		if not PageSize:
			PageSize = 50000

		# assign page size value equal total record if page greater than total record
		if PageSize > NumOfRecord:
			PageSize = NumOfRecord
		
		NumOfPage 	=	0

		if NumOfRecord and PageSize:
			NumOfPage		=	int(math.ceil(float(NumOfRecord)/float(PageSize)))
			LastPageSize	=	NumOfRecord - (int(NumOfRecord)/int(PageSize)) * PageSize
			
		for p in range(0, NumOfPage):
			print p,'===== '*8

			LPageSize 	=	PageSize
			OffSet 		=	p*LPageSize
			
			if NumOfPage - 1 == p:
				LPageSize	=	LastPageSize

			if LPageSize == 0:
				LPageSize = PageSize

			RecordObj		=	FuncGetRecordList(Limit=LPageSize, OffSet=OffSet,**Param1)
			LimitedRecord 	=	RecordObj

			if not PassObj:
				LimitedRecord	=	[getattr(value, PassField) for value in RecordObj] 

			ThreadT 	=	setattr(db, 'session', CLS_CONNECTION_GUARD().ThreadS)
			PoolProc	=	Pool(CPU)
			PoolMap		=	PoolProc.map(partial(FuncProcess, **Param2), LimitedRecord)
			PoolProc.apply_async(time.sleep, (15,))
			PoolProc.close()
			ThreadT = None
		
	except Exception as e:
		raise
	finally:
		pass

def getNumberOfCoreCPU():

	MultiProcessing = MKT_APP_SETTING.query.get('MultiProcessing')

	if not MultiProcessing:
		return 1
	else:
		if MultiProcessing.Value != 'Yes':
			return 1

	CPU 		=	int(math.ceil(multiprocessing.cpu_count()/2.0))
	if CPU > 4:
		CPU = CPU*2-4

	NumberOfCoreCPU = MKT_APP_SETTING.query.get('NumberOfCoreCPU')

	if NumberOfCoreCPU and NumberOfCoreCPU.Value:
		CPU = int(NumberOfCoreCPU.Value)

	return 15